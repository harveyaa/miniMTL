{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "from miniMTL.datasets import *\n",
    "#from miniMTL.models import *\n",
    "from miniMTL.util import *\n",
    "from miniMTL.training import *\n",
    "from miniMTL.hps import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder3(nn.Module):\n",
    "    def __init__(self,dim=58,width=10):\n",
    "        super().__init__()\n",
    "        # in_channels, out_channels\n",
    "        self.fc1 = nn.Linear(dim, width)\n",
    "        #self.batch1 = nn.BatchNorm1d(width)\n",
    "        self.fc2 = nn.Linear(width, width)\n",
    "        #self.batch2 = nn.BatchNorm1d(width)\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        #x = self.batch1(x)\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        #x = self.batch2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class head3(nn.Module):\n",
    "    def __init__(self,width=10):\n",
    "        super().__init__()\n",
    "        self.fc3 = nn.Linear(width,width)\n",
    "        #self.batch3 = nn.BatchNorm1d(width)\n",
    "        self.fc4 = nn.Linear(width,2)\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        #x = self.batch3(x)\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pheno = '/home/harveyaa/Documents/fMRI/data/ukbb_9cohorts/pheno_01-12-21.csv'\n",
    "p_ids = '/home/harveyaa/Documents/masters/MTL/conf_balancing/hybrid'\n",
    "p_conn = '/home/harveyaa/Documents/fMRI/data/ukbb_9cohorts/connectomes/'\n",
    "\n",
    "cases = [#'SZ',\n",
    "        #'BIP',\n",
    "        #'ASD',\n",
    "        'DEL22q11_2',\n",
    "        #'DEL16p11_2',\n",
    "        #'DUP16p11_2',\n",
    "        #'DUP22q11_2',\n",
    "        #'DEL1q21_1',\n",
    "        #'DUP1q21_1'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "DEL22q11_2\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "print('Creating datasets...')\n",
    "data = []\n",
    "for case in cases:\n",
    "    print(case)\n",
    "    data.append(balancedCaseControlDataset(case,p_ids,p_conn,format=0))\n",
    "print('Done!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCED TEST SETS\n",
    "\n",
    "#batch_size=16\n",
    "#head=3\n",
    "#encoder=3\n",
    "#fold=0\n",
    "#\n",
    "#loss_fns = {}\n",
    "#trainloaders = {}\n",
    "#testloaders = {}\n",
    "#decoders = {}\n",
    "#for d, case in zip(data,cases):\n",
    "#    train_idx, test_idx = d.split_data(fold)\n",
    "#    train_d = Subset(d,train_idx)\n",
    "#    test_d = Subset(d,test_idx)\n",
    "#    trainloaders[case] = DataLoader(train_d, batch_size=batch_size, shuffle=True)\n",
    "#    testloaders[case] = DataLoader(test_d, batch_size=batch_size, shuffle=True)\n",
    "#    loss_fns[case] = nn.CrossEntropyLoss()\n",
    "#    #decoders[case] = eval(f'head{head}().double()')\n",
    "#    decoders[case] = head3(width=100).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM TEST SETS\n",
    "\n",
    "batch_size=16\n",
    "head=3\n",
    "encoder=3\n",
    "fold=0\n",
    "\n",
    "# Split data & create loaders & loss fns\n",
    "loss_fns = {}\n",
    "trainloaders = {}\n",
    "testloaders = {}\n",
    "decoders = {}\n",
    "for d, case in zip(data,cases):\n",
    "    train_d, test_d = split_data(d)\n",
    "    trainloaders[case] = DataLoader(train_d, batch_size=batch_size, shuffle=True)\n",
    "    testloaders[case] = DataLoader(test_d, batch_size=batch_size, shuffle=True)\n",
    "    loss_fns[case] = nn.CrossEntropyLoss()\n",
    "    #decoders[case] = eval(f'head{head}().double()')\n",
    "    decoders[case] = head3(width=64).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized HPSModel using: cpu.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = HPSModel(#eval(f'encoder{encoder}().double()'),\n",
    "                encoder3(dim=2080,width=64).double(),\n",
    "                decoders,\n",
    "                loss_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1694,  0.7383,  0.2318,  ..., -0.0056,  0.1872,  0.1571],\n",
       "        [ 0.3065,  0.7976,  0.3194,  ...,  0.7127,  0.6301,  0.2740],\n",
       "        [ 0.2905,  0.9014,  0.1903,  ..., -0.1729,  0.5195,  0.2676],\n",
       "        ...,\n",
       "        [ 0.2226,  0.5564,  0.2904,  ...,  0.8331,  0.5270,  0.1661],\n",
       "        [ 0.3304,  0.9278,  0.3499,  ...,  0.5418,  1.0939,  0.3128],\n",
       "        [ 0.3647,  0.8371,  0.4023,  ...,  0.4919,  0.5511,  0.2485]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(trainloaders['DEL22q11_2']))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5301, 0.4699],\n",
       "        [0.5458, 0.4542],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5284, 0.4716],\n",
       "        [0.4694, 0.5306],\n",
       "        [0.5291, 0.4709],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5190, 0.4810],\n",
       "        [0.5670, 0.4330],\n",
       "        [0.5000, 0.5000]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0 = model.encoder(x)\n",
    "model.decoders['DEL22q11_2'](x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DEL22q11_2': tensor([[0.5055, 0.4945],\n",
       "         [0.5024, 0.4976],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5614, 0.4386],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5377, 0.4623],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5294, 0.4706],\n",
       "         [0.5006, 0.4994],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5121, 0.4879],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5256, 0.4744],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5743, 0.4257]], dtype=torch.float64, grad_fn=<SoftmaxBackward>)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x,['DEL22q11_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpdp65c9ai\n"
     ]
    }
   ],
   "source": [
    "log_dir = tempfile.mkdtemp()\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=50\n",
    "lr = 0.001\n",
    "\n",
    "# Create optimizer & trainer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "trainer = Trainer(optimizer,num_epochs=num_epochs,log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 5/5 [00:00<00:00, 60.58it/s]\n",
      "Epoch 1: 100%|██████████| 5/5 [00:00<00:00, 68.76it/s]\n",
      "Epoch 2: 100%|██████████| 5/5 [00:00<00:00, 68.38it/s]\n",
      "Epoch 3: 100%|██████████| 5/5 [00:00<00:00, 72.72it/s]\n",
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 66.74it/s]\n",
      "Epoch 5: 100%|██████████| 5/5 [00:00<00:00, 67.98it/s]\n",
      "Epoch 6: 100%|██████████| 5/5 [00:00<00:00, 71.26it/s]\n",
      "Epoch 7: 100%|██████████| 5/5 [00:00<00:00, 69.90it/s]\n",
      "Epoch 8: 100%|██████████| 5/5 [00:00<00:00, 68.36it/s]\n",
      "Epoch 9: 100%|██████████| 5/5 [00:00<00:00, 67.03it/s]\n",
      "Epoch 10: 100%|██████████| 5/5 [00:00<00:00, 69.50it/s]\n",
      "Epoch 11: 100%|██████████| 5/5 [00:00<00:00, 70.22it/s]\n",
      "Epoch 12: 100%|██████████| 5/5 [00:00<00:00, 74.46it/s]\n",
      "Epoch 13: 100%|██████████| 5/5 [00:00<00:00, 67.55it/s]\n",
      "Epoch 14: 100%|██████████| 5/5 [00:00<00:00, 66.27it/s]\n",
      "Epoch 15: 100%|██████████| 5/5 [00:00<00:00, 68.56it/s]\n",
      "Epoch 16: 100%|██████████| 5/5 [00:00<00:00, 69.07it/s]\n",
      "Epoch 17: 100%|██████████| 5/5 [00:00<00:00, 69.38it/s]\n",
      "Epoch 18: 100%|██████████| 5/5 [00:00<00:00, 71.17it/s]\n",
      "Epoch 19: 100%|██████████| 5/5 [00:00<00:00, 68.77it/s]\n",
      "Epoch 20: 100%|██████████| 5/5 [00:00<00:00, 70.70it/s]\n",
      "Epoch 21: 100%|██████████| 5/5 [00:00<00:00, 67.13it/s]\n",
      "Epoch 22: 100%|██████████| 5/5 [00:00<00:00, 62.72it/s]\n",
      "Epoch 23: 100%|██████████| 5/5 [00:00<00:00, 70.14it/s]\n",
      "Epoch 24: 100%|██████████| 5/5 [00:00<00:00, 68.75it/s]\n",
      "Epoch 25: 100%|██████████| 5/5 [00:00<00:00, 71.02it/s]\n",
      "Epoch 26: 100%|██████████| 5/5 [00:00<00:00, 76.24it/s]\n",
      "Epoch 27: 100%|██████████| 5/5 [00:00<00:00, 71.70it/s]\n",
      "Epoch 28: 100%|██████████| 5/5 [00:00<00:00, 67.31it/s]\n",
      "Epoch 29: 100%|██████████| 5/5 [00:00<00:00, 69.25it/s]\n",
      "Epoch 30: 100%|██████████| 5/5 [00:00<00:00, 43.17it/s]\n",
      "Epoch 31: 100%|██████████| 5/5 [00:00<00:00, 65.88it/s]\n",
      "Epoch 32: 100%|██████████| 5/5 [00:00<00:00, 50.33it/s]\n",
      "Epoch 33: 100%|██████████| 5/5 [00:00<00:00, 48.47it/s]\n",
      "Epoch 34: 100%|██████████| 5/5 [00:00<00:00, 51.00it/s]\n",
      "Epoch 35: 100%|██████████| 5/5 [00:00<00:00, 68.13it/s]\n",
      "Epoch 36: 100%|██████████| 5/5 [00:00<00:00, 54.43it/s]\n",
      "Epoch 37: 100%|██████████| 5/5 [00:00<00:00, 59.10it/s]\n",
      "Epoch 38: 100%|██████████| 5/5 [00:00<00:00, 70.21it/s]\n",
      "Epoch 39: 100%|██████████| 5/5 [00:00<00:00, 75.64it/s]\n",
      "Epoch 40: 100%|██████████| 5/5 [00:00<00:00, 73.55it/s]\n",
      "Epoch 41: 100%|██████████| 5/5 [00:00<00:00, 77.52it/s]\n",
      "Epoch 42: 100%|██████████| 5/5 [00:00<00:00, 78.87it/s]\n",
      "Epoch 43: 100%|██████████| 5/5 [00:00<00:00, 75.04it/s]\n",
      "Epoch 44: 100%|██████████| 5/5 [00:00<00:00, 78.62it/s]\n",
      "Epoch 45: 100%|██████████| 5/5 [00:00<00:00, 82.62it/s]\n",
      "Epoch 46: 100%|██████████| 5/5 [00:00<00:00, 73.11it/s]\n",
      "Epoch 47: 100%|██████████| 5/5 [00:00<00:00, 74.46it/s]\n",
      "Epoch 48: 100%|██████████| 5/5 [00:00<00:00, 77.48it/s]\n",
      "Epoch 49: 100%|██████████| 5/5 [00:00<00:00, 75.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "trainer.fit(model,trainloaders,testloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEL22q11_2\n",
      "Accuracy:  50.0\n",
      "Loss:  0.07701635339554948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BALANCED\n",
    "# SZ 51.59\n",
    "# BIP 50.0\n",
    "# ASD 47.3\n",
    "\n",
    "# RANDOM\n",
    "# SZ 58.59\n",
    "# BIP 71.875\n",
    "# ASD 49.74\n",
    "\n",
    "# Evaluate at end\n",
    "metrics = model.score(testloaders)\n",
    "for key in metrics.keys():\n",
    "    print()\n",
    "    print(key)\n",
    "    print('Accuracy: ', metrics[key]['accuracy'])\n",
    "    print('Loss: ', metrics[key]['loss'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e9c9c5c044d2ea5dfa7d6bd44b9f426810f06c0ed392c2b436f27e01061f47c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('MTL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
