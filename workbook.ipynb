{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Create torch datasets\n",
    "- Create dataloaders\n",
    "- Create simple CNN model (from paper)\n",
    "    - Random reformat\n",
    "    - Figure out dimensions of conv layers\n",
    "    - Batchnorm (after conv layer only?)\n",
    "    - 3 dense layers of w/ 64 units\n",
    "    - Relu\n",
    "    - Softmax\n",
    "- Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harveyaa/miniconda3/envs/MTL/lib/python3.7/site-packages/ipykernel_launcher.py:5: DtypeWarning: Columns (7,8,12,13,14,19,20,24,27,31,42,43,44,49,51,59,60,62,64,65,68,101,121,163) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "p_pheno = '/home/harveyaa/Documents/fMRI/data/ukbb_9cohorts/pheno_01-12-21.csv'\n",
    "p_conn = '/home/harveyaa/Documents/fMRI/data/ukbb_9cohorts/connectomes_01-12-21.csv'\n",
    "\n",
    "#data = ukbbSexDataset(p_pheno,p_conn)\n",
    "data = caseControlDataset('SZ',p_pheno,p_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_data(data)\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=16, shuffle=True)\n",
    "testloader = DataLoader(test, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ukbbSex(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # in_channels, out_channels\n",
    "        self.conv = nn.Conv2d(1, 256, (40,1))\n",
    "        self.batch0 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*52, 64)\n",
    "        self.batch1 = nn.BatchNorm1d(64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.batch2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64,2)\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv(torch.unsqueeze(x,dim=1))\n",
    "        x = self.batch0(x)\n",
    "        x = x.view(x.size()[0],-1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.batch1(x)\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.batch2(x)\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ukbbSex().double()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.614644  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 54.7%, Avg loss: 0.042169 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.652532  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 62.5%, Avg loss: 0.040722 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.679898  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.039045 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.505100  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 65.6%, Avg loss: 0.038314 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.493570  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 63.3%, Avg loss: 0.040883 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.611237  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.036259 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.415378  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.037392 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.404512  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 64.8%, Avg loss: 0.039477 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.385077  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.036863 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.323865  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.035728 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.318871  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.035931 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.378528  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 71.1%, Avg loss: 0.036735 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.313751  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 69.5%, Avg loss: 0.037510 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.387921  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 68.8%, Avg loss: 0.036406 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.361908  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.036055 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.375171  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.033903 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.443818  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.035511 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.376118  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.035038 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.317612  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 73.4%, Avg loss: 0.035639 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.315622  [    0/  510]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.034583 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(trainloader, model, loss_fn, optimizer)\n",
    "    test(testloader, model)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e9c9c5c044d2ea5dfa7d6bd44b9f426810f06c0ed392c2b436f27e01061f47c"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('MTL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
