{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harveyaa/miniconda3/envs/fmri/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from miniMTL.datasets import caseControlDataset\n",
    "from miniMTL.models import head0, encoder100\n",
    "from miniMTL.training import Trainer\n",
    "\n",
    "from miniMTL.hps import HPSModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pheno = '/Users/harveyaa/Documents/masters/data/pheno_26-01-22.csv'\n",
    "p_ids = '/Users/harveyaa/Documents/masters/neuropsych_mtl/datasets/cv_folds/intrasite/'\n",
    "p_conn = os.path.join('/Users/harveyaa/Documents/masters/data/','connectomes')\n",
    "\n",
    "p_out = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "ASD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harveyaa/Documents/masters/miniMTL/miniMTL/datasets.py:200: DtypeWarning: Columns (7,8,12,13,14,19,20,24,27,31,42,43,44,49,51,59,60,62,64,65,68,101,121,163) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pheno = pd.read_csv(pheno_path,index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harveyaa/Documents/masters/miniMTL/miniMTL/datasets.py:200: DtypeWarning: Columns (7,8,12,13,14,19,20,24,27,31,42,43,44,49,51,59,60,62,64,65,68,101,121,163) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pheno = pd.read_csv(pheno_path,index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SZ\n",
      "Done!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harveyaa/Documents/masters/miniMTL/miniMTL/datasets.py:200: DtypeWarning: Columns (7,8,12,13,14,19,20,24,27,31,42,43,44,49,51,59,60,62,64,65,68,101,121,163) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pheno = pd.read_csv(pheno_path,index_col=0)\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "print('Creating datasets...')\n",
    "#cases = ['ASD','BIP','SZ','DEL22q11_2','DUP22q11_2','DEL1q21_1','DUP1q21_1','DEL16p11_2','DUP16p11_2']\n",
    "cases = ['ASD','BIP','SZ']\n",
    "#cases = ['DEL22q11_2']\n",
    "#cases = ['DEL1q21_1','DUP1q21_1']\n",
    "data = []\n",
    "for case in cases:\n",
    "    print(case)\n",
    "    data.append(caseControlDataset(case,p_pheno,id_path=p_ids,conn_path=p_conn,\n",
    "                                    type='conn',strategy='balanced',format=2))\n",
    "print('Done!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized HPSModel using: cpu.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split data & create loaders & loss fns\n",
    "bs = 16\n",
    "\n",
    "loss_fns = {}\n",
    "trainloaders = {}\n",
    "testloaders = {}\n",
    "decoders = {}\n",
    "for d, case in zip(data,cases):\n",
    "    train_idx, test_idx = d.split_data(random=False,fold=4)\n",
    "    train_d = Subset(d,train_idx)\n",
    "    test_d = Subset(d,test_idx)\n",
    "    trainloaders[case] = DataLoader(train_d, batch_size=bs, shuffle=True)\n",
    "    testloaders[case] = DataLoader(test_d, batch_size=bs, shuffle=True)\n",
    "    loss_fns[case] = nn.CrossEntropyLoss()\n",
    "    decoders[case] = eval(f'head{0}().double()')\n",
    "    \n",
    "hps = HPSModel(eval(f'encoder{100}().double()'),\n",
    "                decoders,\n",
    "                loss_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer & trainer\n",
    "optim_hps = torch.optim.Adam(hps.parameters(), lr=1e-3)\n",
    "trainer_hps = Trainer(optim_hps,log_dir=p_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 88/88 [02:23<00:00,  1.63s/it]\n",
      "Epoch 1:  99%|█████████▉| 87/88 [02:20<00:01,  1.62s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/harveyaa/Documents/masters/miniMTL/workbook.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/harveyaa/Documents/masters/miniMTL/workbook.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/harveyaa/Documents/masters/miniMTL/workbook.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer_hps\u001b[39m.\u001b[39;49mfit(hps,trainloaders,testloaders,num_epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/masters/miniMTL/miniMTL/training.py:124\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, dataloaders, test_dataloaders, num_epochs, shuffle)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    123\u001b[0m \u001b[39m# Evaluate model\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m metrics \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mscore(test_dataloaders)\n\u001b[1;32m    125\u001b[0m \u001b[39mfor\u001b[39;00m task \u001b[39min\u001b[39;00m tasks:\n\u001b[1;32m    126\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter\u001b[39m.\u001b[39madd_scalar(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss/test/\u001b[39m\u001b[39m{\u001b[39;00mtask\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,metrics[task][\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m],epoch_num)\n",
      "File \u001b[0;32m~/Documents/masters/miniMTL/miniMTL/hps.py:107\u001b[0m, in \u001b[0;36mHPSModel.score\u001b[0;34m(self, dataloaders)\u001b[0m\n\u001b[1;32m    105\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)                    \n\u001b[1;32m    106\u001b[0m Y \u001b[39m=\u001b[39m Y_dict[task]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 107\u001b[0m pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(X,[task])[task]\n\u001b[1;32m    109\u001b[0m \u001b[39m# Do this to average properly over the whole list of batches\u001b[39;00m\n\u001b[1;32m    110\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_fn(pred, Y)\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/masters/miniMTL/miniMTL/hps.py:50\u001b[0m, in \u001b[0;36mHPSModel.forward\u001b[0;34m(self, X, task_names)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,X,task_names):\n\u001b[1;32m     37\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m    ----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m        Dictionary from task name to associated output.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(X)\n\u001b[1;32m     52\u001b[0m     outputs \u001b[39m=\u001b[39m {}\n\u001b[1;32m     53\u001b[0m     \u001b[39mfor\u001b[39;00m task \u001b[39min\u001b[39;00m task_names:\n",
      "File \u001b[0;32m~/miniconda3/envs/fmri/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/masters/miniMTL/miniMTL/models.py:72\u001b[0m, in \u001b[0;36mencoder100.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch0(x)\n\u001b[1;32m     71\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(x\u001b[39m.\u001b[39msize()[\u001b[39m0\u001b[39m],\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x)))\n\u001b[1;32m     73\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch1(x)\n\u001b[1;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/fmri/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/fmri/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "trainer_hps.fit(hps,trainloaders,testloaders,num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASD\n",
      "Accuracy:  46.27659574468085\n",
      "Loss:  0.04457285473529006\n",
      "\n",
      "BIP\n",
      "Accuracy:  67.74193548387096\n",
      "Loss:  0.03442825679932411\n",
      "\n",
      "SZ\n",
      "Accuracy:  67.71653543307087\n",
      "Loss:  0.03822824655208791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate at end\n",
    "metrics_hps = hps.score(testloaders)\n",
    "for key in metrics_hps.keys():\n",
    "    print()\n",
    "    print(key)\n",
    "    print('Accuracy: ', metrics_hps[key]['accuracy'])\n",
    "    print('Loss: ', metrics_hps[key]['loss'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ASD': {'accuracy': 57.97872340425532, 'loss': 0.1369718253028779},\n",
       " 'BIP': {'accuracy': 77.41935483870968, 'loss': 0.06530408812576415},\n",
       " 'SZ': {'accuracy': 75.59055118110236, 'loss': 0.09313200944603715},\n",
       " 'DEL22q11_2': {'accuracy': 76.47058823529412, 'loss': 0.06881384382984729},\n",
       " 'DUP22q11_2': {'accuracy': 50.0, 'loss': 0.22229325533492122},\n",
       " 'DEL1q21_1': {'accuracy': 30.0, 'loss': 0.4331672511722159},\n",
       " 'DUP1q21_1': {'accuracy': 42.857142857142854, 'loss': 0.44524299089875496},\n",
       " 'DEL16p11_2': {'accuracy': 41.66666666666667, 'loss': 0.3415105960658535},\n",
       " 'DUP16p11_2': {'accuracy': 50.0, 'loss': 0.3076967009626213}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('fmri')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ea07d7e26f64274b859969024e9bc122a0aaa5b386426249452447396636cf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
